---
title: "Building an xDS Control Plane in Python: Embracing Dynamic Networking"
author: eunsang
pubDatetime: 2025-08-03T10:00:00Z
modDatetime: 2025-08-03T10:00:00Z
slug: building-xds-control-plane-python-embracing-dynamic-networking
featured: false
draft: false
tags: ["envoy", "xds", "grpc", "python", "network", "buf", "uv"]
description: ""
--- 

## Decoding the Envoy Control Plane: An xDS Overview

So there I was, trying to teach Envoy how to think.

The idea is solid: instead of hardcoding your proxy config in static YAML, you spin up a separate control plane that tells Envoy what to do — live, over gRPC.

The xDS API family is extensive, and it can take a bit of time to understand what each component does. Here's a breakdown of the key members:

* **LDS (Listener Discovery Service)** – Configures which ports Envoy should listen on and how to process incoming traffic.
* **CDS (Cluster Discovery Service)** – Defines clusters, representing the upstream services Envoy can connect to.
* **RDS (Route Discovery Service)** – Specifies routing rules, such as directing requests for `/users` to the user service.
* **EDS (Endpoint Discovery Service)** – Provides the actual IP addresses of healthy instances within a cluster.

And here’s the catch: these configs need to arrive in the right order. You can’t route to a cluster that doesn’t exist. You can’t define an endpoint before the cluster is known. Enter *ADS* — Aggregated Discovery Service.

Instead of juggling four separate gRPC streams (one per service), ADS gives you a single, unified stream where everything flows through one channel. CDS → EDS → RDS, in perfect order. Envoy connects once, and the control plane sequences the updates.

## SotW ADS in Action

Envoy’s docs spell out four xDS transport variants along two axes—State-of-the-World vs. incremental, and per-type vs. aggregated streams:

> * **State of the World (Basic xDS):** SotW, separate gRPC stream for each resource type
> * **Incremental xDS:** incremental, separate gRPC stream for each resource type
> * **Aggregated Discovery Service (ADS):** SotW, aggregate stream for all resource types
> * **Incremental ADS:** incremental, aggregate stream for all resource types

Our Python control plane sits in the **Aggregated Discovery Service** (ADS) + **State-of-the-World** corner:

* **Single gRPC stream for everything.** Envoy calls only [`StreamAggregatedResources`](https://github.com/CynicDog/Envoy-xDS-server-in-python/blob/52925c42c187eeb6b657b7af0af2193b3111069e/xds_server.py#L231) on our `AggregatedDiscoveryServiceServicer`, and carries LDS, CDS, RDS, EDS, etc., as logical sub-streams over that one channel.
* **Full snapshots on every update.** Whenever Envoy’s `version_info` is empty, doesn’t match our server version, or it NACKs, we bundle up **all** of the requested resources of that type and send them together—no delta logic, no piecemeal updates.
* **Guaranteed ordering.** By delivering Listeners → Clusters → Routes → Endpoints on the same wire, we sidestep “I got my routes before my cluster existed” errors.

If you later need “send-only-what-changed” behavior or lazy loading at scale, you can switch to **Incremental ADS** (`DeltaAggregatedResources`). But for a lean, easy-to-debug demo, SotW ADS gives us exactly the right mix of simplicity and correctness.

## First Contact: How Envoy Finds Its Control Plane

Before our Python server can work its magic, the Envoy proxy needs to be told one simple, critical thing: where to find the xDS server. This is the sole job of the static `envoy.yaml` file. It’s the "bootstrap" configuration that gets the proxy’s lights on and points it in the right direction.

My [`envoy.yaml`](https://github.com/CynicDog/Envoy-xDS-server-in-python/blob/main/envoy.yaml) shows this perfectly. It’s mostly static housekeeping, but the key sections bridge the static world with our dynamic one.

* **The Control Plane Address:** The `dynamic_resources` section is where the magic begins. It tells Envoy that all its configuration—Listeners, Clusters, Routes—will come from a dynamic source via the *Aggregated Discovery Service* (`ads_config`). Critically, it points to a *static cluster* named `xds_cluster` for this purpose.
* **A Static Cluster for a Dynamic World:** This `xds_cluster` is a bit of an anachronism—a static cluster defined in a file—but it’s essential. Its only purpose is to define a host (`xds-server`) and a port (`5678`) so Envoy knows how to establish the initial gRPC connection to our Python server.

Think of it this way: our `envoy.yaml` isn’t the destination. It’s the ignition key and map to the real destination—our Python xDS server.

## Rebuilding Envoy’s Request Path in Python

This server isn’t just wiring together gRPC calls—it’s a live re-creation of how an HTTP request flows through Envoy, from socket to upstream. Instead of static YAML, we assemble the whole chain dynamically in Python using Envoy’s Protobuf APIs.

At the edge of the mesh, [`generate_listener_config()`](https://github.com/CynicDog/Envoy-xDS-server-in-python/blob/52925c42c187eeb6b657b7af0af2193b3111069e/xds_server.py#L75) sets up a Listener on port `15001`. It’s the front door for incoming connections. Inside, we drop in an [`HttpConnectionManager`](https://github.com/CynicDog/Envoy-xDS-server-in-python/blob/52925c42c187eeb6b657b7af0af2193b3111069e/xds_server.py#L113)—Envoy’s L7-aware filter that converts raw TCP into HTTP. From there, traffic moves through a minimal HTTP filter chain, with the `router` filter handling the actual routing logic.

Routing is kept simple: all paths (`/`) forward to the `httpbin_service` cluster, defined in [`generate_cluster_config()`](https://github.com/CynicDog/Envoy-xDS-server-in-python/blob/52925c42c187eeb6b657b7af0af2193b3111069e/xds_server.py#L164). This cluster uses logical DNS to resolve the hostname `httpbin`, assuming it’s reachable within the network (like a Docker container), and load balances requests—round-robin style—across any resolved endpoints.

The whole flow—Listener to filter chain, HTTP parsing to routing, and finally, to the upstream Cluster—is streamed to Envoy by the `XdsServer`, which implements the Aggregated Discovery Service (ADS). It only sends updates when the config actually changes, using versioning and content hashes to track state.

This setup is small, but it mirrors the real-world anatomy of an Envoy deployment—just with Python and Protobufs instead of static config files.

## Conclusion

Getting an xDS server *up and running* is one thing — but truly understanding the path to that point is a whole different story. This project felt like a microcosm of modern microservice challenges: complex, sometimes maddening, but rewarding.

What really stuck with me is that this isn’t about static files anymore. Static YAML is simple to read, but brittle and slow to change. xDS flips the script: it’s a living, breathing system — a continuous control loop that adapts on the fly.

Our Python server is a mini version of that philosophy. It’s not a static snapshot; it’s an active, intelligent agent streaming updates, ready to evolve as the network changes.

This isn’t just about building a functional server—it’s about adopting a new mindset: treating dynamic networking as code. The future isn’t defined by flawless YAML files, but by systems that communicate, adapt, and reconfigure themselves in real time.
